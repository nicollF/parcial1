{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Primer Punto (Parte 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Considere los ejemplos vistos en clase, en los que se analizó la implementación de los modelos: k-nn, regresión lineal, regresión logística. Realice hiperparametrización y validación cruzada usando (i) GridSearchCV y Pipeline vs (ii) Manualmente, sin usar GridSearchCV y Pipeline (Use ciclos FOR, WHILE, etc,. . . ). Verifique que los scores obtenidos en los ítems (i)-(ii) son los mismos. Los ejercicios son los siguientes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breast Cancer: (KNN, LogisticRegression) Decida cual es la métrica de mayor importancia en la aplicación de detección de cancer (métrica de negocio). Utilice esta métrica para la evaluación y selección del modelo y justifique su respuesta. Los resultados deben ser presentados usando el Cuadro 1. El estudiante que obtenga el mejor score con esta métrica, será premiado con una décima para el corte. Los datos deben ser cargados mediante el siguiente par de líneas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mglearn\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametrización y validación cruzada.\n",
    "1. GridSearchCV y pipeline\n",
    "2. manualmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los modelos que realizaremos a continuación, hemos decido que la mejor métrica de negocio en esta ocasión es *recall*, ya que, queremos limitar el npumero de falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **K-nn**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos primeramente el modelo k-nn utilizando GridsearchCV y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando métrica: precision\n",
      "Mejores parámetros para k-NN con precision: {'knn__n_neighbors': 10}\n",
      "Mejor score para k-NN con precision: 0.9296070701784988\n",
      "\n",
      "Evaluando métrica: recall\n",
      "Mejores parámetros para k-NN con recall: {'knn__n_neighbors': 100}\n",
      "Mejor score para k-NN con recall: 0.9918367346938777\n",
      "\n",
      "Evaluando métrica: f1\n",
      "Mejores parámetros para k-NN con f1: {'knn__n_neighbors': 10}\n",
      "Mejor score para k-NN con f1: 0.9457994660175351\n",
      "\n",
      "Evaluando métrica: roc_auc\n",
      "Mejores parámetros para k-NN con roc_auc: {'knn__n_neighbors': 100}\n",
      "Mejor score para k-NN con roc_auc: 0.9609260478384902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3, random_state=10)\n",
    "\n",
    "# Definir el pipeline\n",
    "knn_pipeline = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Definir los hiperparámetros a explorar\n",
    "neighbors = {'knn__n_neighbors': [1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Lista de métricas a evaluar\n",
    "scoring_metrics = ['precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "for metric in scoring_metrics:\n",
    "    print(f\"Evaluando métrica: {metric}\")\n",
    "    \n",
    "    # Realizar la búsqueda de hiperparámetros usando GridSearchCV\n",
    "    knngridsearch = GridSearchCV(knn_pipeline, neighbors, cv=5, scoring=metric)\n",
    "    knngridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    # Imprimir los mejores parámetros y el mejor score para la métrica actual\n",
    "    print(f\"Mejores parámetros para k-NN con {metric}: {knngridsearch.best_params_}\")\n",
    "    print(f\"Mejor score para k-NN con {metric}: {knngridsearch.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de efectuar el modelo, obtuvimos que el mejor parámetro para k-nn era 100, con un score de 99% usando la metrica *recall*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regresión logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, tambien realizamos el modelo para la regresión logística haciendo uso de Gridsearch y pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para reglog: {'lr__C': 1}\n",
      "Mejor score para reglog (según recall): 0.963265306122449\n",
      "Mejor precision: 0.9381179796543677\n",
      "Mejor recall: 0.963265306122449\n",
      "Mejor f1: 0.9496007714229572\n",
      "Mejor AUC: 0.9888259820057055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regrelog_pipe = Pipeline([('lr', LogisticRegression())])\n",
    "\n",
    "# Definir los hiperparámetros a probar\n",
    "reglog = {'lr__C': [1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Definir las métricas que se van a evaluar\n",
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'AUC': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Realizar GridSearchCV con múltiples métricas y refit en 'recall' (puedes cambiarlo según la métrica que prefieras)\n",
    "reglog_gridsearch = GridSearchCV(regrelog_pipe, reglog, cv=5, scoring=scoring, refit='recall')\n",
    "\n",
    "# Ajustar el modelo\n",
    "reglog_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor score\n",
    "print(\"Mejores parámetros para reglog:\", reglog_gridsearch.best_params_)\n",
    "print(\"Mejor score para reglog (según recall):\", reglog_gridsearch.best_score_)\n",
    "\n",
    "# Resultados de todas las métricas para los mejores parámetros\n",
    "results = reglog_gridsearch.cv_results_\n",
    "for metric in scoring:\n",
    "    print(f\"Mejor {metric}: {results[f'mean_test_{metric}'][reglog_gridsearch.best_index_]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos que el mejor parámetro para la regresión logística es 1, con un score del 96% usando la métrica *recall*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelos manuales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-nn (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.99183673\n",
      "Best parameters:  {'n_neighbors': 100}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for n_neighbors in [1, 10, 100, 1000, 10000]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)        \n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring=\"recall\") \n",
    "    score = np.mean(scores)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'n_neighbors': n_neighbors}\n",
    "print(\"Best cross-validation accuracy: {:.8f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de efectuar el modelo k-nn manual, podemos observar que obtuvimos el mismo resultado al modelo utilizando GridsearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logística (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para reglog: {'lr__C': 1}\n",
      "Mejor score para reglog: 0.963265306122449\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for C in [1, 10, 100, 1000, 10000]:\n",
    "    regrelogis = LogisticRegression(C = C)\n",
    "    scores = cross_val_score(regrelogis, X_train, y_train, cv=5, scoring='recall')\n",
    "    meanscores = np.mean(scores)\n",
    "    \n",
    "    if meanscores > best_score:\n",
    "        best_score = meanscores\n",
    "        best_parameters = {'lr__C': C }\n",
    "\n",
    "print(\"Mejores parámetros para reglog:\",best_parameters)\n",
    "print(\"Mejor score para reglog:\", best_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que con el modelo de regresión logística de forma manual hemos obtenido el mismo resultado que con el modelo con el que fue utilizado el GridsearchCV. Obtuvimos que el mejor parámetro para este es 1 con un score de 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|l|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Modelo} & \\textbf{Precisión} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{AUC} \\\\ \\hline\n",
    "\\textbf{K-NN} & 0.9296070701784988 & 0.9918367346938777 & 0.9457994660175351 & 0.9609260478384902 \\\\ \\hline\n",
    "\\textbf{Regresión Logística} &  0.9381179796543677 & 0.963265306122449 & 0.9496007714229572 & 0.9888259820057055 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
